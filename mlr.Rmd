---
title: "Project 2 - MLR"
author: "Group 7"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
library(leaps)
library(MASS)
library(tidyverse)
library(faraway)
```

```{r}
kc <- read.csv('kc_house_data.csv', header = TRUE)
```

```{r}
filtered_kc <- kc %>%
  mutate(
    renovated = factor(ifelse(yr_renovated > 0, 1, 0)),
    view_bin = factor(view), # changed to factor since price and view has no clear linear relationship
    waterfront = factor(waterfront),
  ) %>%
  subset(select = -c(id, date, zipcode, yr_renovated))

set.seed(1) ##for reproducibility to get the same split
sample<-sample.int(nrow(filtered_kc), floor(.50*nrow(filtered_kc)), replace = F)
train<-filtered_kc[sample, ] ##training data frame
test<-filtered_kc[-sample, ] ##test data frame
```

```{r}
sqft_cols <- c('sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15')
count_cols <- c('bedrooms', 'bathrooms', 'floors')
index_cols <- c('view', 'condition', 'grade')
binary_col <- c('waterfront', 'grade_bin')
```
```{r}
train[, c('price', sqft_cols)] %>%
  cor
```

- From the features measured in square feet, sqft_living has the highest correlation with price at 0.7077887.
- sqft_living is highly correlated with sqft_above and sqft_living15.
- Based on the description, sqft_living should be the sum of sqft_above and sqft_basement.
- From the features measured in square feet, we will use sqft_living as a predictor for the model.

```{r}
train[, c('price', count_cols)] %>%
  cor
```

- Since the number of bathrooms and bedrooms are usually used for housing sales, we will use those two factors as predictors.

```{r}
train[, c('price', index_cols)] %>%
  cor
```

- From the index features, grade has the highest correlation with price at 0.6697105.
- We will use grade as a predictor in the model

In addition to these, we will use location features as predictors:
- long
- lat
- waterfront
- view_bin (factorized version of view)

We will also be using recency of the building:
- yr_built
- renovated


```{r}
filtered_kc <- filtered_kc %>%
  subset(select = c(price, sqft_living, bedrooms, bathrooms, grade, lat, long, waterfront, view, yr_built, renovated))

set.seed(1) ##for reproducibility to get the same split
sample<-sample.int(nrow(filtered_kc), floor(.50*nrow(filtered_kc)), replace = F)
train<-filtered_kc[sample, ] ##training data frame
test<-filtered_kc[-sample, ] ##test data frame
```

```{r}
regnull <- lm(price ~ 1, data = train)
regfull <- lm(price ~ ., data = train)
```

### Stepwise
```{r}
step(regnull, scope=list(lower = regnull, upper = regfull), direction = 'both')
```
```{r}
step(regfull, scope=list(lower = regnull, upper = regfull), direction = 'both')
```
```{r}
summary(regfull)
```
```{r}
reduced <- lm(price ~ sqft_living + bedrooms + bathrooms + grade + view + lat + long + yr_built + waterfront, data = train)
anova(reduced, regfull)
```
Based on ANOVA F test, we reject the null and go with the reduced model without `renovated`

```{r}
summary(reduced)
```
### Detecting multicollinearity

```{r}
vif(reduced)
```

Based on the VIFs, there are no signs of multicollinearity.

### Check for interaction terms??

### Regression Assumptions
```{r}
res <- data.frame(reduced$fitted.values, reduced$residuals)
res %>%
  ggplot(aes(x = reduced.fitted.values, y = reduced.residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = 'red') +
  labs(x = 'Fitted y', y = 'Residuals', title = 'Residual Plot')
```
```{r}
 acf(reduced$residuals, main = 'ACF Plot of Residuals')
```
```{r}
qqnorm(reduced$residuals)
qqline(reduced$residuals, col = 'red')
```
```{r}
boxcox(reduced, lambda = seq(0, 0.4, 0.01))
```
Transform the response variable
y* = log(y)
Applied log so that the coefficients can still be interpreted.

```{r}
train <- train %>% 
  mutate(ystar = log(price))

transformed <- lm(ystar ~ sqft_living + bedrooms + bathrooms + grade + view + lat + long + yr_built + waterfront, data = train)
summary(transformed)
```
`long` appears to be insignificant after transforming `price`

```{r}
transformed_reduced <- lm(ystar ~ sqft_living + bedrooms + bathrooms + grade + view + lat + yr_built + waterfront, data = train)
summary(transformed_reduced)
```

```{r}
res <- data.frame(fitted = transformed_reduced$fitted.values, residuals = transformed_reduced$residuals)
res %>%
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = 'red') +
  labs(x = 'Fitted y', y = 'Residuals', title = 'Residual Plot')
```
```{r}
acf(transformed_reduced$residuals, main = 'ACF Plot of Residuals')
```
```{r}
qqnorm(transformed_reduced$residuals)
qqline(transformed_reduced$residuals, col = 'red')
```
```{r}
boxcox(transformed_reduced)
```
Passes the regression assumptions after transforming y.
Will check with prof woo/xiang tomorrow if box cox is okay (near 1)
